{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNugHHHaTqd4MiaaNihZo8C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annapinyaeva/SPPR/blob/main/SPPR3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e8Ar9DI9Ipf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install surprise\n",
        "from surprise import *\n",
        "from surprise.model_selection import KFold\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.accuracy import rmse\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from collections import defaultdict\n",
        "from surprise import accuracy\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Подключили файлы\n",
        "rating = pd.read_csv('/rating.csv')\n",
        "rating.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "BHj9d9zH9Jxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anime = pd.read_csv('/anime.csv')\n",
        "anime.head()\n"
      ],
      "metadata": {
        "id": "XWEdKx4nQrTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating.info()\n"
      ],
      "metadata": {
        "id": "m2-S23k2SXdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(line_format='user item rating', sep=\"\\t\")\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "df = Dataset.load_from_df(rating, reader)"
      ],
      "metadata": {
        "id": "oYl293mRdaME"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "18qaXruOmMRq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating.rating.unique()"
      ],
      "metadata": {
        "id": "7qeJOMywl-No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "id": "gZZezbSvgMzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        \n",
        "        \n",
        "        '''))\n"
      ],
      "metadata": {
        "id": "oBYpRohAeqdw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configure_plotly_browser_state()\n",
        "from plotly.offline import init_notebook_mode, plot, iplot\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "init_notebook_mode(connected = True)\n",
        "\n",
        "data = rating[\"rating\"].value_counts().sort_index(ascending=False)\n",
        "trace = go.Bar(x = data.index,\n",
        "               text = ['{:.1f} %'.format(val) for val in (data.values / rating.shape[0] * 100)],\n",
        "               textposition = 'auto',\n",
        "               textfont = dict(color = '#000000'),\n",
        "               y = data.values,\n",
        "               )\n",
        "# Create layout\n",
        "layout = dict(title = 'Distribution Of {} ratings'.format(rating.shape[0]),\n",
        "              xaxis = dict(title = 'Rating'),\n",
        "              yaxis = dict(title = 'Count'))\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)\n",
        "     \n"
      ],
      "metadata": {
        "id": "r88eDIrOex4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configure_plotly_browser_state()\n",
        "\n",
        "\n",
        "data = rating.groupby('anime_id')['rating'].count().clip(upper=50)\n",
        "# Create trace\n",
        "trace = go.Histogram(x = data.values,\n",
        "                     name = 'Ratings',\n",
        "                     xbins = dict(start = 0,\n",
        "                                  end = 50,\n",
        "                                  size = 2))\n",
        "# Create layout\n",
        "layout = go.Layout(title = 'Distribution Of Number of Ratings Per Item (Clipped at 50)',\n",
        "                   xaxis = dict(title = 'Number of Ratings Per Item'),\n",
        "                   yaxis = dict(title = 'Count'),\n",
        "                   bargap = 0.2)\n",
        "\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "metadata": {
        "id": "6w64iD-Pe2t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n"
      ],
      "metadata": {
        "id": "spbNTqp5fa20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configure_plotly_browser_state()\n",
        "from plotly.offline import init_notebook_mode, plot, iplot\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "init_notebook_mode(connected = True)"
      ],
      "metadata": {
        "id": "-VKuUaYGhnWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "ghlgkEU2iWRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "HHFnExF2lpO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# param_grid = {'n_factors': [25, 30, 35, 40], 'n_epochs': [15, 20, 25], 'lr_all': [0.001, 0.003, 0.005, 0.008],\n",
        "#               'reg_all': [0.08, 0.1, 0.15]}\n",
        "\n",
        "param_grid = {'n_factors': [25], 'n_epochs': [15], 'lr_all': [0.001, 0.003],\n",
        "              'reg_all': [0.08, 0.1]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, joblib_verbose = 432)\n",
        "\n",
        "gs.fit(df)\n",
        "\n",
        "algo = gs.best_estimator['rmse']\n",
        "print(gs.best_score['rmse'])\n",
        "print(gs.best_params['rmse'])\n",
        "\n",
        "#Assigning values\n",
        "t = gs.best_params\n",
        "factors = t['rmse']['n_factors']\n",
        "epochs = t['rmse']['n_epochs']\n",
        "lr_value = t['rmse']['lr_all']\n",
        "reg_value = t['rmse']['reg_all']"
      ],
      "metadata": {
        "id": "Q2KbK3MohzUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(df, test_size=0.25)\n",
        "algo = SVD(n_factors=40, n_epochs=25, lr_all=0.008, reg_all=0.08)\n",
        "predictions = algo.fit(trainset).test(testset)\n",
        "accuracy.rmse(predictions)\n"
      ],
      "metadata": {
        "id": "-gutCSdQsEUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Iu(uid):\n",
        "    \"\"\" \n",
        "    args: \n",
        "      uid: the id of the user\n",
        "    returns: \n",
        "      the number of items rated by the user\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
        "    except ValueError: # user was not part of the trainset\n",
        "        return 0\n",
        "    \n",
        "def get_Ui(iid):\n",
        "    \"\"\" \n",
        "    args:\n",
        "      iid: the raw id of the item\n",
        "    returns:\n",
        "      the number of users that have rated the item.\n",
        "    \"\"\"\n",
        "    try: \n",
        "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "    \n",
        "df_predictions = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
        "df_predictions['Iu'] = df_predictions.uid.apply(get_Iu)\n",
        "df_predictions['Ui'] = df_predictions.iid.apply(get_Ui)\n",
        "df_predictions['err'] = abs(df_predictions.est - df_predictions.rui)\n",
        "df_predictions.head()\n"
      ],
      "metadata": {
        "id": "_FqEPUxHs0qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_predictions = df_predictions.sort_values(by='err')[:10]\n",
        "worst_predictions = df_predictions.sort_values(by='err')[-10:]\n",
        "\n",
        "temp = rating.loc[rating['anime_id'] == '0195153448']['rating']\n",
        "configure_plotly_browser_state()\n",
        "\n",
        "# Create trace\n",
        "trace = go.Histogram(x = temp.values,\n",
        "                     name = 'Ratings',\n",
        "                     xbins = dict(start = 0,\n",
        "                                  end = 5, size=.3))\n",
        " # Create layout\n",
        "layout = go.Layout(title = 'Number of ratings item 3996 has received',\n",
        "                   xaxis = dict(title = 'Number of Ratings Per Item'),\n",
        "                   yaxis = dict(title = 'Count'),\n",
        "                   bargap = 0.2)\n",
        "# Create plot\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "iplot(fig)"
      ],
      "metadata": {
        "id": "mcqmkRX1tJmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = []\n",
        "\n",
        "for threshold in np.arange(0, 5.5, 0.5):\n",
        "    tp=0\n",
        "    fn=0\n",
        "    fp=0\n",
        "    tn=0\n",
        "    temp = []\n",
        "\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        if(true_r>=threshold):\n",
        "            if(est>=threshold):\n",
        "                tp = tp+1\n",
        "            else:\n",
        "                fn = fn+1\n",
        "        else:\n",
        "            if(est>=threshold):\n",
        "                fp = fp+1\n",
        "            else:\n",
        "                tn = tn+1   \n",
        "\n",
        "        if tp == 0:\n",
        "            precision = 0\n",
        "            recall = 0\n",
        "            f1 = 0\n",
        "        else:\n",
        "            precision = tp / (tp + fp)\n",
        "            recall = tp / (tp + fn)\n",
        "            f1 = 2 * (precision * recall) / (precision + recall)  \n",
        "\n",
        "    temp = [threshold, tp,fp,tn ,fn, precision, recall, f1]\n",
        "    final.append(temp)\n",
        "\n",
        "results = pd.DataFrame(final)\n",
        "results.rename(columns={0:'threshold', 1:'tp', 2: 'fp', 3: 'tn', 4:'fn', 5: 'Precision', 6:'Recall', 7:'F1'}, inplace=True)\n",
        "results"
      ],
      "metadata": {
        "id": "pxrZgPryt5wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_at_k(predictions, k, threshold):\n",
        "    '''Return precision and recall at k metrics for each user.'''\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
        "\n",
        "    return precisions, recalls"
      ],
      "metadata": {
        "id": "nJiUUvV1uLXg"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "for i in range(2, 11):\n",
        "    precisions, recalls = precision_recall_at_k(predictions, k=i, threshold=2.5)\n",
        "\n",
        "    # Precision and recall can then be averaged over all users\n",
        "    prec = sum(prec for prec in precisions.values()) / len(precisions)\n",
        "    rec = sum(rec for rec in recalls.values()) / len(recalls)\n",
        "    results.append({'K': i, 'Precision': prec, 'Recall': rec})\n",
        "    \n",
        "\n",
        "results"
      ],
      "metadata": {
        "id": "iEuYMBi6uPo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "sXMKOGMDuTdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rec=[]\n",
        "Precision=[]\n",
        "Recall=[]\n",
        "for i in range(0,9):\n",
        "    Rec.append(results[i]['K'])\n",
        "    Precision.append(results[i]['Precision'])\n",
        "    Recall.append(results[i]['Recall'])\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(Rec, Precision)\n",
        "plt.xlabel('# of Recommendations')\n",
        "plt.ylabel('Precision')\n",
        "plt2 = plt.twinx()\n",
        "plt2.plot(Rec, Recall, 'r')\n",
        "plt.ylabel('Recall')\n",
        "for tl in plt2.get_yticklabels():\n",
        "    tl.set_color('r')"
      ],
      "metadata": {
        "id": "TzpyssUAuYqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = df.build_full_trainset()   #Build on entire data set\n",
        "testset = trainset.build_testset()\n",
        "algo = SVD(n_factors= 25, n_epochs= 15, lr_all= 0.003, reg_all= 0.08)\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Predict ratings for all pairs (u, i) that are NOT in the training set.\n",
        "\n",
        "\n",
        "#Predicting the ratings for testset\n",
        "predictions = algo.test(testset)"
      ],
      "metadata": {
        "id": "P2GYEe51vOxo"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_predictions(predictions):\n",
        "    \n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)    \n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "p1fFQTeGvU0C"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pred = get_all_predictions(predictions)"
      ],
      "metadata": {
        "id": "D4utt0l3vXsR"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "\n",
        "for uid, user_ratings in all_pred.items():\n",
        "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "    all_pred[uid] = user_ratings[:n]"
      ],
      "metadata": {
        "id": "0ZGgoDqVvake"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = pd.DataFrame.from_dict(all_pred,orient='index')\n",
        "tmp_transpose = tmp.transpose()\n",
        "tmp"
      ],
      "metadata": {
        "id": "hNaqpuB_xLaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(user_id):\n",
        "    results = tmp_transpose.loc[user_id ]\n",
        "    return results"
      ],
      "metadata": {
        "id": "llqAI2k3xcSs"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = get_predictions(2)\n",
        "results"
      ],
      "metadata": {
        "id": "6WV3v6gJxqDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_anime_ids=[]\n",
        "for x in range(1, n+1):\n",
        "      recommended_anime_ids.append(results[x][0])\n",
        "\n",
        "recommended_anime_ids"
      ],
      "metadata": {
        "id": "MNoqnb01xtne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anime.head()\n",
        "recommended_anime = anime[anime['anime_id'].isin(recommended_anime_ids)]"
      ],
      "metadata": {
        "id": "3SKAePHHyBUa"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_anime\n"
      ],
      "metadata": {
        "id": "IEl8ZlTP72dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = rating[rating['user_id'] == 25].sort_values(\"rating\", ascending = False)\n",
        "temp.head()"
      ],
      "metadata": {
        "id": "0t7mSUDO_fQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.shape"
      ],
      "metadata": {
        "id": "Mq6QNuL3AK8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_anime_ids = temp['anime_id']\n",
        "user_history = anime[anime['anime_id'].isin(history_anime_ids)]"
      ],
      "metadata": {
        "id": "69ho_HKxAR5m"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_history[:n]"
      ],
      "metadata": {
        "id": "-Wdmy8hFAw0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_anime"
      ],
      "metadata": {
        "id": "0TTW7-TDA4J2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}